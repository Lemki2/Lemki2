---
layout: post
title: Assignment 3 - Image Analysis
excerpt: "Working with images"
modified: 04/21/2023, 2:40:00
tags: [artificial intelligence, text, text analysis]
comments: true
category: blog
---
IMAGES ASSIGNMENT
Introduction to Digital Humanities -  Professor David Wrisley
Lemisa Selimi

### Context
About Image Analysis
1st Phase
2nd Phase
Reflection

ABOUT IMAGE ANALYSIS

If you give it a thought, at first image analysis may seem like a simple and easy thing  but it is more complex than just clustering some images based on their colors! 
	
	Have you wondered how the computer actually reads images?

Just like with almost any other technological advance, the purpose of image recognition and analysis is to increase efficiency as well, to do something that humans cannot do, better and faster. Just like it is mentioned in Drucker’s book, “For an individual to watch all of these, working ten hours a day, would take ten thousand days . . . about thirty years. Automated techniques for searching and sorting clearly have a purpose”. (122). Similar to Moretti’s motive for researching textual analysis, Manovich started his research with the question of how to analyze a group of images. It is complex because many factors such as metadata are used for comparison when it comes to images, such as the way it is stored, as pixel-based, vector-based, or other different values if it is black and white or colored. Things like size, medium, artist, collection, provenance, date, and other information that is not visible, are taken into consideration. (Drucker, 122). As we have seen in our class, just for a single picture, there are thousands of numbers stored as data, which is great but somehow a black box because we do not exactly know how they are created. The thing to be emphasized is that even after all this preciseness too, computers lack the ability to recognize images like humans do, such as emotions or more subtle things, however there is great improvement, which is still continuing. And it is not necessary for computers to be perfect anyway, I think. There are disadvantages too because , however, some mistakes are worth the great job and effortless results that these tools give us! Humans have other abilities and computers have more higher capacity abilities, we do not necessarily need to create a competition between these but rather contemplate on and work on complementing these, of course, for good purposes.


1ST PHASE
	For this phase, I just roughly chose some photos such as objects, mirrors, and paintings, and created a collection out of them, without putting them into categories.
What I found out was that although I did not have a very specific way of choosing images, the platform still seems to have recognized some patterns in the images such as putting two toys close to each other on the upper side or two women on the right side or similarly two sea pictures in the middle. For the other images, it seems to either separate them individually or put them together which makes me wonder based on what this has been done since I do not find the images similar or in the same category. 

<img src="/images/1st image grid.png" style="width:80%; height:50%; margin-left:10%;" />

2ND PHASE
	For this phase, I have chosen nine categories, with 100 photos in total, 10 in each category and 20 in the mountains category:
Animals
Caves
Forests
Lakes
Monuments
Mountains
People
Plains
Plants
My domain of research was the area of Albania and Kosovo.
	Mostly, finding what I was searching for was easy except when it came to people as it was giving photos of people in groups and in specific themes such as politics or war. So, I searched more specifically for actors, singers, and similar people. Interestingly, I found some popular Albanians whom I didn't even know before through this search such as “Jim Belushi”, or some interesting things like a plant hypericum perforatum which seems to be a plant of divination or animals such as barn owls.
	When it comes to the computer's job of classifying these, we can see different levels of accuracy for different categories, however, I think it has done a great job overall.  For example, it classified around five faces and put them together in the left downside, around 9 caves in the right downside. Also, most of the right side is filled with pictures of mountains and forests and some lakes, which is not very accurately distributed and organized but I still think it is a big thing. Could this mean that as of now it is easier for a computer to grasp bigger themes like “nature” instead of “mountain” or “forest” specifically? Who knows. I think it was interesting to not have very sharply distinguishable categories of photos because that would not be so challenging for the computer or would not give us the best understanding. Doing this allows us to demystify its workings a bit more and see its limitations. For example, Orange seems to have classified one of the images from the lake category as a mountain because of the background. Now, we can ask based on what did it do this, and how does it decide on which part to focus when it comes to classifying one image, which is the main and which the background?
	
<img src="/images/2nd phase image grid.png" style="width:80%; height:50%; margin-left:10%;" />

> From the confusion matrix, we can see that caves, mountains, people, and plants are among the categories with highest accuracy, which is surprising. Getting 19 out of 20 images of mountains accurate, I think, is a great accomplishment, however, it has mistaken around 3 images of lakes and 2 plains for mountains, which is ok. And then, monuments and people, with only two mistakes. 
<img src="/images/confusion matrix.png" style="width:80%; height:50%; margin-left:10%;" />

REFLECTION

My choices were mainly on the objects represented in images such as mountains or people and that is what I wanted to see if the computer is able to distinguish from each other because other types of comparison like color are not so hard. 
	
	How is the computer able to put pixels and all the data into a category?

What I did in step 2 relates to Salvaggio's claim "When we make a dataset, we operate within specific cultural, political, social, and economic contexts. How we frame a dataset is much the way we frame an image. We have a question we'd like to investigate. We find samples of the world that represent that question. We snap the photo when those samples come into specific alignments", because most of this is interpretive and it’s true that a lot of bias is included as well.

Just like Professor Wrisley mentioned in class, I agree with the statement that once one publishes something, it is not their property anymore, it is not private. So, I do not think at all that there are any ethical issues with the collection of images I took from the internet or what I did with them. Furthermore, images I took are mountains, plains, and monuments, which are not really private in themselves. Although I encountered a source from which I could download images, afterward I found out they were closed images, which means someone put a copyright in them. Not surprisingly however, some of the same images I found while I continued searching online. At this point, I am questioning the purpose of putting a copyright to a photo of a mountain. Why would someone consider it private when it is nature, land, something not personal? Just because of having captured it? That is not sufficient reason.

Arnold and Tilton use the expression "distant viewing", imitating the expression "distant reading" we learned earlier in the term. How can you relate your study to their article? Is their definition "distant viewing, is distinguished from other approaches by making explicit the interpretive nature of extracting semantic metadata from images" helpful for what you did?
This is helpful because that is what I have done. When analyzing images at scale, one needs to explicitly decide what is ‘actually’ being represented by each object prior to aggregating and analyzing the collection. (Arnold). How else would we test a computer's ability to recognize images other than creating some system to which a comparison can be made? Now, this is not to say that the way we see the world is accurate or perfect but this is our experience and level of knowing. This is the main system and we want to get as close as possible to such a system but with far more efficiency. That’s why interpretive work and creation of categories of images is necessary for this process. Distant viewing is more complex than distant reading because the data does not have explicit meaning. Visual forms such as paintings and photographs illustrate and circulate concepts through characteristics such as lines, color, shape, and size.2 An image serves as a link to the object being represented by sharing similar qualities. (Arnold).
The difference between elements contained in the raw image and the extracted structured information used to digitally represent the image within a database is known as a semantic gap.

I do not post pictures, however, I have used Google Photos for storing so many of my photos before, which is similar to posting them since they are no longer private as they are stored in the cloud. Now that I am reflecting on this, I remember I have shared pictures on some messaging platforms too. 


Works Cited
Drucker, Johanna. “The Digital Humanities Coursebook: An Introduction to Digital Methods for Research and Scholarship.” Digital Scholarship in the Humanities, vol. 37, no. 3, Oxford UP, July 2022, pp. 912–15. https://doi.org/10.1093/llc/fqac044.
Arnold, Taylor B., and Lauren Tilton. “Distant Viewing: Analyzing Large Visual Corpora.” Digital Scholarship in the Humanities, vol. 34, no. Supplement_1, Oxford UP, Dec. 2019, pp. i3–16. https://doi.org/10.1093/llc/fqz013.

